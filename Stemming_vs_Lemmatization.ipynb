{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPPVc/Kos8rkE0UMkuXKwFP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MeSamiulIslam/NLP_Learning/blob/main/Stemming_vs_Lemmatization.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Stemming\n",
        "## Stemming is the process of reducing a word to its word to its **word stem** that affixes to suffixes and prefixes r to the roots of words knows as lemma. Stemming is important in Natural language understaning (NLU) and Natural language processing (NLP)"
      ],
      "metadata": {
        "id": "RF6s6x5YWUNt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "[Documentation NLTK PorterStemmer](https://www.nltk.org/_modules/nltk/stem/porter.html#PorterStemmer)"
      ],
      "metadata": {
        "id": "dOXUzD6vXVFf"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Jf0D3B9zThna"
      },
      "outputs": [],
      "source": [
        "from nltk.stem import PorterStemmer"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stemming = PorterStemmer()"
      ],
      "metadata": {
        "id": "XTbYMz8aW7mC"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "words = [\"eating\", \"eats\", \"eaten\", \"writing\", \"programming\", \"programs\", \"history\", \"finally\", \"finalized\"]"
      ],
      "metadata": {
        "id": "zDForyLqXKC8"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for word in words:\n",
        "  print(word + \"--->\" +stemming.stem(word))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Yq97txGZCxz",
        "outputId": "71f3796a-2885-41ee-9241-657f48f0854c"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "eating--->eat\n",
            "eats--->eat\n",
            "eaten--->eaten\n",
            "writing--->write\n",
            "programming--->program\n",
            "programs--->program\n",
            "history--->histori\n",
            "finally--->final\n",
            "finalized--->final\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stemming.stem(\"congratulations\") #Problem with some words, like this."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 37
        },
        "id": "LZjHNoVXZT8B",
        "outputId": "24e8ec5c-8077-4374-e1d0-8451e2d682ed"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'congratul'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stemming.stem(\"understanding\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 37
        },
        "id": "rJO-s3D3Z6_K",
        "outputId": "355c5534-e9a7-436e-dce6-b4b32a00749c"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'understand'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stemming.stem(\"sitting\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 37
        },
        "id": "JzY1VPX-aAhR",
        "outputId": "37d4b0c2-a134-4723-fc33-4bf39dd78d3d"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'sit'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Lancaster Stemming Algorithm\n",
        "[Documentation](https://www.nltk.org/api/nltk.stem.lancaster.html)"
      ],
      "metadata": {
        "id": "BEwfNVGaafFR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import LancasterStemmer"
      ],
      "metadata": {
        "id": "yjX5kv24aEvG"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lancaster = LancasterStemmer()"
      ],
      "metadata": {
        "id": "QoKR3hhobEA6"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for word in words:\n",
        "  print(word + \"--->\" + lancaster.stem(word))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bfmwt9ufbMCg",
        "outputId": "3c97a5dc-7250-4c97-c0bc-fc014cafd2ad"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "eating--->eat\n",
            "eats--->eat\n",
            "eaten--->eat\n",
            "writing--->writ\n",
            "programming--->program\n",
            "programs--->program\n",
            "history--->hist\n",
            "finally--->fin\n",
            "finalized--->fin\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Porter stemmer far better then Lancester stemmer but some specific problems Lancester stemmer perform better."
      ],
      "metadata": {
        "id": "qAl_3saZbpys"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# NLTK has RegexpStemmer class with the help of which we can easily implement Regular Expression Stemmer algorithm. It basically takes a single regular expression and remove any prefix or suffix that matches the expression."
      ],
      "metadata": {
        "id": "iRt_BhjzcTGK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "[Documentation](https://www.nltk.org/api/nltk.stem.regexp.html)"
      ],
      "metadata": {
        "id": "zL0HxzSjdd10"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import RegexpStemmer"
      ],
      "metadata": {
        "id": "5IeisfOecuxu"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reg_stemmer = RegexpStemmer('ing$|s$|e$|able$', min=4) #first peramitter is Regular expression and then word limit."
      ],
      "metadata": {
        "id": "cyoRlMuqc1rZ"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reg_stemmer.stem(\"eating\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 37
        },
        "id": "tcZkmeAIdCtg",
        "outputId": "4a307ccb-df02-44d6-c471-7bc32fc1a2d8"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'eat'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "reg_stemmer = RegexpStemmer('ing|s$|e$|able$', min=4)"
      ],
      "metadata": {
        "id": "rYSbTEkSehDd"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reg_stemmer.stem(\"ingplaying\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 37
        },
        "id": "KLadD7X7dkdC",
        "outputId": "6f89b84b-dc33-4b15-a4b2-7b0fcf24b1b6"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'play'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "reg_stemmer = RegexpStemmer('ing$|s$|e$|able$', min=4)"
      ],
      "metadata": {
        "id": "mGLaQk45eorv"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reg_stemmer.stem(\"ingplaying\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 37
        },
        "id": "CavbayhUe28_",
        "outputId": "00ef288d-24cd-4942-8020-97165511ff8f"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'ingplay'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "reg_stemmer.stem('advisable')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 37
        },
        "id": "NnsYbf-tfPfG",
        "outputId": "2ee76428-ee3c-48c2-dbde-e76c58312788"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'advis'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "reg_stemmer.stem('mass')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 37
        },
        "id": "Kv-D5Ty4flRv",
        "outputId": "3169cba1-add5-491c-b084-c2f9302d4521"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'mas'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "f-2cAdV0ftOH"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Snowball Stemmer\n",
        "[Documentation](https://www.nltk.org/api/nltk.stem.snowball.html)"
      ],
      "metadata": {
        "id": "GWX9l-_vgCdj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import SnowballStemmer"
      ],
      "metadata": {
        "id": "zOh4wVx7gKff"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "snowball_stemmer = SnowballStemmer('english', ignore_stopwords= False) #fast peramitter is Language and 2nd one is if you want to stemm stop words then FALSE."
      ],
      "metadata": {
        "id": "AMOuI2fYga7u"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for word in words:\n",
        "  print(word + \"--->\" + snowball_stemmer.stem(word))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5QIyA4f0hGye",
        "outputId": "639db7b3-bfa2-47b7-eb0f-d5d7285bc13d"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "eating--->eat\n",
            "eats--->eat\n",
            "eaten--->eaten\n",
            "writing--->write\n",
            "programming--->program\n",
            "programs--->program\n",
            "history--->histori\n",
            "finally--->final\n",
            "finalized--->final\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# consider Porter and Snowball"
      ],
      "metadata": {
        "id": "kF8alKKTher-"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stemming.stem(\"fairly\"),stemming.stem(\"sportingly\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ESl68BxqiCNO",
        "outputId": "b7925551-34f5-46b1-ec5c-d1b041274787"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('fairli', 'sportingli')"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "snowball_stemmer.stem(\"fairly\"), snowball_stemmer.stem(\"sportingly\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ERMsTghYiQ96",
        "outputId": "a84e5ae8-2fd4-4e26-8ca0-ca9b5c940810"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('fair', 'sport')"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Lemmatization Techinque"
      ],
      "metadata": {
        "id": "zabNEVlLiozr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## wordnet Lemmatizer\n",
        "lemmatization technique is like stemming. the output we will get after lemmatization is called 'lemma', which is a root word rather than root stem, the output of stemming. After lemmatization, we will be getting a valid word that means the same thing.\n",
        "NLTK provides WordNetLemmatizer class which is a thin wrapper around the wordnet corpus. This class uses morphy() function to the WordNet CorpusReader class to find a lemma."
      ],
      "metadata": {
        "id": "L7S5OMEbixXC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "[Documentation](https://www.nltk.org/api/nltk.stem.wordnet.html)"
      ],
      "metadata": {
        "id": "uPJIXI-ek0gv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('wordnet')\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "lemmatizer = WordNetLemmatizer()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R1e-4Auxjr91",
        "outputId": "16f69447-3b0c-4818-b6e7-c834345552fe"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for word in words:\n",
        "  print(word + \"--->\" + lemmatizer.lemmatize(word)) #default pos is noun=n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ASHM_vwdlH_d",
        "outputId": "d5967cc9-a096-44eb-a06a-fcf934dad465"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "eating--->eating\n",
            "eats--->eats\n",
            "eaten--->eaten\n",
            "writing--->writing\n",
            "programming--->programming\n",
            "programs--->program\n",
            "history--->history\n",
            "finally--->finally\n",
            "finalized--->finalized\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#first peramitter is word and 2nd is Pos tag [eg. Noun=n, Verb=v, adjective=a, adverb=r]"
      ],
      "metadata": {
        "id": "sKYiPo21m4wo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for word in words:\n",
        "  print(word + \"--->\" + lemmatizer.lemmatize(word, pos='v'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mQvpbCWomjCc",
        "outputId": "a5045b8e-fdb2-4807-f6af-e2756eeec680"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "eating--->eat\n",
            "eats--->eat\n",
            "eaten--->eat\n",
            "writing--->write\n",
            "programming--->program\n",
            "programs--->program\n",
            "history--->history\n",
            "finally--->finally\n",
            "finalized--->finalize\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lemmatizer.lemmatize(\"better\", pos='n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 37
        },
        "id": "wWvoJPLlnI5k",
        "outputId": "ed18564d-a6da-4558-bd15-a28bd04a3cca"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'better'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lemmatizer.lemmatize(\"better\", pos='v')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 37
        },
        "id": "1K8jDOALnzB0",
        "outputId": "441f9d28-76af-4779-99ea-036344a5716c"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'better'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lemmatizer.lemmatize(\"better\", pos='r')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 37
        },
        "id": "vJGy2i5Pn39n",
        "outputId": "bcecb51a-1b42-444d-9d75-cc21871666da"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'well'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lemmatizer.lemmatize(\"better\", pos='a')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 37
        },
        "id": "IbAm9pfRn5vP",
        "outputId": "2667ff44-2033-4e8f-c48b-65728275cb60"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'good'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Some use case\n",
        "\n",
        "\n",
        "*   Sentiment Analysis = Stemming\n",
        "*   Chatbot = Lemmatization"
      ],
      "metadata": {
        "id": "sTrN_gr_oLC_"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UpkYoGFDoWyj"
      },
      "execution_count": 32,
      "outputs": []
    }
  ]
}